# Hadiths-Scrapper-NLP-Pipeline

## Project Description

The HadithScraperNLP project is aimed at scraping Hadiths from various pages of the website https://mawdoo3.com/, storing the raw data in a MongoDB database, and applying Natural Language Processing (NLP) techniques on the scraped text. The NLP pipeline includes processes such as text cleaning, tokenization, stemming, lemmatization using different libraries, Part-of-Speech (POS) tagging, and Named Entity Recognition (NER).

## Technologies Used

The project utilizes the following technologies and libraries:

- Python: The primary programming language used for development.
- Scrapy: A Python framework for web scraping, employed for extracting data from HTML pages.
- MongoDB: A NoSQL database used for storing the raw Hadith data.
- PyMongo - A Python driver for MongoDB.
- NLTK: A natural language processing library for Python, used for text preprocessing tasks such as tokenization and stopwords removal, and yes it worked well!! :)
- Stanza: A Python NLP library for Arabic, utilized for lemmatization, POS tagging, and NER.
- Qalsadi: A Python library for Arabic lemmatization, to compare it with the result of Stanza.
- Regular Expressions (Regex): Used for text pattern matching and cleaning.
- unicodedata: Employed for normalizing Unicode characters.

## Project Structure 

-myspider.py: Contains the Scrapy spider for scraping Hadiths from specified URLs and storing them in MongoDB.
-nlp_pipeline.py: Implements the NLP pipeline including text cleaning, tokenization, stemming, lemmatization, POS tagging, and NER.
-main.py: Retrieves data from MongoDB, applies the NLP pipeline, and stores the processed data in JSON format.
-outputs: Directory containing the output JSON files generated by the main.py script.

WebScrapping-NLP-pipeline/

├── outputs/

│   ├── cleaned_data.json
│   ├── lemmatized_data_qalsadi.json
│   ├── lemmatized_data_stanza.json
│   ├── ner_data.json
│   ├── pos_data.json
│   ├── stemmed_data.json
│   └── tokenized_data.json
└── spiders/
    ├── __init__.py
    ├── main.py
    ├── myspider.py
    ├── nlp_pipeline.py
├── __init__.py
├── items.py
├── middlewares.py
├── pipelines.py
└── settings.py
├── scrapy.cfg
